{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Freq Model\n",
    "\n",
    "在这个notebook中，我们用训练高频模型。这里的代码做为模型更新线程的基础。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pm(s):\n",
    "    '''\n",
    "    提取序列中的正负号 ( e.g. [-3, 2, -2, 3] -> [-1, 1, -1, 1] )\n",
    "    s : array\n",
    "    '''\n",
    "    s_pm = np.zeros(s.shape)\n",
    "    for i in range(len(s)):\n",
    "        if s[i] > 0:\n",
    "            s_pm[i] = 1\n",
    "        if s[i] < 0:\n",
    "            s_pm[i] = -1\n",
    "    return s_pm\n",
    "def calc_accuracy(pred, real):\n",
    "    return (1 + np.sum(to_pm(pred) * to_pm(real))/len(pred))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas34 = pd.read_csv('data/alphas34.csv').set_index('Unnamed: 0')\n",
    "alphasbasic = pd.read_csv('data/alphasbasic.csv').set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     print(alphasbasic.loc[: ,'obj10':].corr().iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphaall = alphasbasic.join(alphas34.iloc[:, 52:]).iloc[:, 49:] \\\n",
    "#     .replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# alphaall.replace({False: 0, True: 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphaall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaall_sub = alphasbasic.join(alphas34.iloc[:, 52:]).iloc[:, 49:60] \\\n",
    "    .replace([np.inf, -np.inf], np.nan).dropna()\n",
    "alphaall_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     print(alphaall.corr().iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(61):\n",
    "#     print([alphaall.columns[i], alphaall.iloc[:, i].mean(), alphaall.iloc[:, i].var()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(61):\n",
    "#     plt.figure()\n",
    "#     alphaall.iloc[:, i].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data_shuf = shuffle(alphaall_sub, random_state = 2021)\n",
    "\n",
    "y_train = data_shuf.iloc[:1000000, 0].values\n",
    "X_train = data_shuf.iloc[:1000000, 1:].values\n",
    "y_validate = data_shuf.iloc[1000000:1300000, 0].values\n",
    "X_validate = data_shuf.iloc[1000000:1300000, 1:].values\n",
    "y_test = data_shuf.iloc[1300000:, 0].values\n",
    "X_test = data_shuf.iloc[1300000:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "hidden_layer_sizes = (10, 10)\n",
    "max_iter = 10\n",
    "alpha = 0.0001\n",
    "learning_rate_init = 0.0005\n",
    "\n",
    "nnr = MLPRegressor(hidden_layer_sizes = hidden_layer_sizes, \n",
    "                   max_iter = max_iter, \n",
    "                   alpha = alpha, \n",
    "                   learning_rate_init = learning_rate_init, \n",
    "                   random_state = 2021, verbose = True)\n",
    "\n",
    "nnr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = nnr.predict(X_train)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(y_train_pred, y_train, 'go')\n",
    "plt.plot([-1,1], [-1,1], 'grey', ls = '--', label = 'y = x')\n",
    "plt.plot([-1,1], np.poly1d(np.polyfit(y_train_pred, y_train, 1))([-1,1]), 'g--', label = 'fit')\n",
    "plt.xlabel('pred')\n",
    "plt.ylabel('real')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "mean_squared_error(y_train_pred, y_train), calc_accuracy(y_train_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate_pred = nnr.predict(X_validate)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(y_validate_pred, y_validate, 'go')\n",
    "plt.plot([-1,1], [-1,1], 'grey', ls = '--', label = 'y = x')\n",
    "plt.plot([-1,1], np.poly1d(np.polyfit(y_validate_pred, y_validate, 1))([-1,1]), 'g--', label = 'fit')\n",
    "plt.xlabel('pred')\n",
    "plt.ylabel('real')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "mean_squared_error(y_validate_pred, y_validate), calc_accuracy(y_validate_pred, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate[y_validate_pred.argsort()[-100:]] # long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate[y_validate_pred.argsort()[:100]] # short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(nnr, open('Models/MLP_SOIR.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
